{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pykdtree.kdtree import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normals_and_curvature_within_threshold(data, threshold):\n",
    "    data = np.asarray(data) \n",
    "    nbrs = NearestNeighbors(radius=threshold).fit(data) \n",
    "\n",
    "    normals = np.zeros(data.shape) \n",
    "    curvature = np.zeros(data.shape[0]) \n",
    "    mean_curvature = np.zeros(data.shape[0]) \n",
    "\n",
    "    # Iterate over each point in the dataset\n",
    "    for i, point in enumerate(data):\n",
    "        # Find neighbors within the threshold\n",
    "        distances, indices = nbrs.radius_neighbors([point], return_distance=True)\n",
    "\n",
    "        # Flatten the list of indices and remove the point itself\n",
    "        neighbors = data[indices[0]] \n",
    "\n",
    "        total_curvature = 0.0 \n",
    "\n",
    "        # Skip points with insufficient neighbors (e.g., less than the dimensionality of space)\n",
    "        if len(neighbors) < data.shape[1]:\n",
    "            continue\n",
    "\n",
    "        # Center the neighbors around the point\n",
    "        centered_neighbors = neighbors - point\n",
    "\n",
    "        # Perform PCA using Singular Value Decomposition (SVD)\n",
    "        covariance_matrix = np.cov(centered_neighbors, rowvar=False)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)  # Eigenvalues and eigenvectors\n",
    "\n",
    "        # The normal vector is the eigenvector corresponding to the smallest eigenvalue\n",
    "        normal_vector = eigenvectors[:, 0]\n",
    "        normals[i] = normal_vector        \n",
    "\n",
    "        # Compute curvature based on change in normal vector angles\n",
    "        for neighbor in neighbors:\n",
    "            if np.array_equal(point, neighbor):\n",
    "                continue\n",
    "\n",
    "            # Find neighbors of the current neighbor\n",
    "            neighbor_distances, neighbor_indices = nbrs.radius_neighbors([neighbor], return_distance=True)\n",
    "            secondary_neighbors = data[neighbor_indices[0]] - neighbor\n",
    "\n",
    "            # Skip if there are insufficient neighbors for the neighbor point\n",
    "            if len(secondary_neighbors) < data.shape[1]:\n",
    "                continue\n",
    "\n",
    "            # Fit PCA to secondary neighbors\n",
    "            secondary_cov_matrix = np.cov(secondary_neighbors, rowvar=False)\n",
    "            _, secondary_eigenvectors = np.linalg.eigh(secondary_cov_matrix)\n",
    "            secondary_normal_vector = secondary_eigenvectors[:, 0]\n",
    "\n",
    "            # Compute the angle between the normal vectors\n",
    "            dot_product = np.dot(normal_vector, secondary_normal_vector)\n",
    "            dot_product = np.clip(dot_product, -1.0, 1.0)  # Clip to avoid numerical issues\n",
    "            angle_change = np.arccos(dot_product)\n",
    "\n",
    "            # Estimate curvature based on the angle change and distance between the points\n",
    "            distance_change = np.linalg.norm(neighbor - point)\n",
    "            if distance_change > 0:\n",
    "                curvature_point = angle_change / distance_change\n",
    "                total_curvature += curvature_point\n",
    "        \n",
    "        curvature[i] = total_curvature \n",
    "        mean_curvature[i] = total_curvature / len(neighbors) \n",
    "\n",
    "        # print progress every 10% \n",
    "        if i % (data.shape[0] // 100) == 0:\n",
    "            print(f\"Progress: {i / data.shape[0] * 100:.2f}%\")\n",
    "\n",
    "    return normals, curvature, mean_curvature   \n",
    "\n",
    "def compute_normals_and_curvature_knn(data, k):\n",
    "    data = np.asarray(data) \n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(data)  # +1 to include the point itself\n",
    "\n",
    "    normals = np.zeros(data.shape) \n",
    "    curvature = np.zeros(data.shape[0]) \n",
    "    mean_curvature = np.zeros(data.shape[0]) \n",
    "\n",
    "    # Iterate over each point in the dataset\n",
    "    for i, point in enumerate(data):\n",
    "        # Find k-nearest neighbors\n",
    "        distances, indices = nbrs.kneighbors([point])\n",
    "\n",
    "        # Get the neighbors, excluding the point itself\n",
    "        neighbors = data[indices[0][1:]]  # Exclude the first index, which is the point itself\n",
    "\n",
    "        total_curvature = 0.0 \n",
    "\n",
    "        # Skip points with insufficient neighbors (less than the dimensionality of space)\n",
    "        if len(neighbors) < data.shape[1]:\n",
    "            continue\n",
    "\n",
    "        # Center the neighbors around the point\n",
    "        centered_neighbors = neighbors - point\n",
    "\n",
    "        # Perform PCA using Singular Value Decomposition (SVD)\n",
    "        covariance_matrix = np.cov(centered_neighbors, rowvar=False)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)  # Eigenvalues and eigenvectors\n",
    "\n",
    "        # The normal vector is the eigenvector corresponding to the smallest eigenvalue\n",
    "        normal_vector = eigenvectors[:, 0]\n",
    "        normals[i] = normal_vector        \n",
    "\n",
    "        # Compute curvature based on change in normal vector angles\n",
    "        for neighbor in neighbors:\n",
    "            if np.array_equal(point, neighbor):\n",
    "                continue\n",
    "\n",
    "            # Find k-nearest neighbors of the current neighbor\n",
    "            neighbor_distances, neighbor_indices = nbrs.kneighbors([neighbor])\n",
    "            secondary_neighbors = data[neighbor_indices[0][1:]] - neighbor  # Exclude the neighbor itself\n",
    "\n",
    "            # Skip if there are insufficient neighbors for the neighbor point\n",
    "            if len(secondary_neighbors) < data.shape[1]:\n",
    "                continue\n",
    "\n",
    "            # Fit PCA to secondary neighbors\n",
    "            secondary_cov_matrix = np.cov(secondary_neighbors, rowvar=False)\n",
    "            _, secondary_eigenvectors = np.linalg.eigh(secondary_cov_matrix)\n",
    "            secondary_normal_vector = secondary_eigenvectors[:, 0]\n",
    "\n",
    "            # Compute the angle between the normal vectors\n",
    "            dot_product = np.dot(normal_vector, secondary_normal_vector)\n",
    "            dot_product = np.clip(dot_product, -1.0, 1.0)  # Clip to avoid numerical issues\n",
    "            angle_change = np.arccos(dot_product)\n",
    "\n",
    "            # Estimate curvature based on the angle change and distance between the points\n",
    "            distance_change = np.linalg.norm(neighbor - point)\n",
    "            if distance_change > 0:\n",
    "                curvature_point = angle_change / distance_change\n",
    "                total_curvature += curvature_point\n",
    "        \n",
    "        curvature[i] = total_curvature \n",
    "        mean_curvature[i] = total_curvature / len(neighbors) \n",
    "\n",
    "        # Print progress every 10% \n",
    "        if i % (data.shape[0] // 100) == 0:\n",
    "            print(f\"Progress: {i / data.shape[0] * 100:.2f}%\")\n",
    "\n",
    "    return normals, curvature, mean_curvature\n",
    "\n",
    "\n",
    "def compute_normals(data, k):\n",
    "    data = np.asarray(data) \n",
    "    kdtree = KDTree(data) \n",
    "    print(\"Done building KDTree\") \n",
    "    _, all_indices = kdtree.query(data, k=k+1) \n",
    "    print(\"Done querying KDTree\") \n",
    "    normals = np.zeros(data.shape) \n",
    "\n",
    "    # Iterate over each point in the dataset\n",
    "    for i, point in enumerate(data):\n",
    "        # Find k-nearest neighbors\n",
    "        # distances, indices = nbrs.kneighbors([point])\n",
    "        indices = all_indices[i] \n",
    "\n",
    "\n",
    "        # Get the neighbors, excluding the point itself\n",
    "        neighbors = data[indices]  # Exclude the first index, which is the point itself\n",
    "\n",
    "        total_curvature = 0.0 \n",
    "\n",
    "        # Skip points with insufficient neighbors (less than the dimensionality of space)\n",
    "        if len(neighbors) < data.shape[1]:\n",
    "            continue\n",
    "\n",
    "        # Center the neighbors around the point\n",
    "        centered_neighbors = neighbors - point\n",
    "\n",
    "        # Perform PCA using Singular Value Decomposition (SVD)\n",
    "        covariance_matrix = np.cov(centered_neighbors, rowvar=False)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)  # Eigenvalues and eigenvectors\n",
    "\n",
    "        # The normal vector is the eigenvector corresponding to the smallest eigenvalue\n",
    "        normal_vector = eigenvectors[:, 0]\n",
    "        normals[i] = normal_vector        \n",
    "\n",
    "        # Print progress every 10% \n",
    "        if i % (data.shape[0] // 100) == 0:\n",
    "            print(f\"Progress: {i / data.shape[0] * 100:.2f}%\")\n",
    "\n",
    "    return normals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map = pd.read_csv('../data/extrusion_real_map.csv') \n",
    "# filepath = \"/media/rp/Elements/abhay_ws/real_contact_data/slotted_circle_rounded/slotted_circle_aut_map_1.pkl\"\n",
    "filepath = \"/media/rp/Elements/abhay_ws/mujoco_contact_graph_generation/results/cross_rounded_data/reverse_perturb_v4/processed_data/cross_rounded_peg_contact_map_sim.csv\"\n",
    "if filepath.endswith('.csv'):\n",
    "    filetype = \".csv\" \n",
    "    map = pd.read_csv(filepath) \n",
    "elif filepath.endswith('.pkl'): \n",
    "    filetype = \".pkl\" \n",
    "    map = pd.read_pickle(filepath) \n",
    "map = map[['x', 'y', 'z', 'a', 'b', 'c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building KDTree\n",
      "Done querying KDTree\n",
      "Progress: 0.00%\n",
      "Progress: 1.00%\n",
      "Progress: 2.00%\n",
      "Progress: 3.00%\n",
      "Progress: 4.00%\n",
      "Progress: 5.00%\n",
      "Progress: 6.00%\n",
      "Progress: 7.00%\n",
      "Progress: 8.00%\n",
      "Progress: 9.00%\n",
      "Progress: 10.00%\n",
      "Progress: 11.00%\n",
      "Progress: 12.00%\n",
      "Progress: 13.00%\n",
      "Progress: 14.00%\n",
      "Progress: 15.00%\n",
      "Progress: 16.00%\n",
      "Progress: 17.00%\n",
      "Progress: 18.00%\n",
      "Progress: 19.00%\n",
      "Progress: 20.00%\n",
      "Progress: 21.00%\n",
      "Progress: 22.00%\n",
      "Progress: 23.00%\n",
      "Progress: 24.00%\n",
      "Progress: 25.00%\n",
      "Progress: 26.00%\n",
      "Progress: 27.00%\n",
      "Progress: 28.00%\n",
      "Progress: 29.00%\n",
      "Progress: 30.00%\n",
      "Progress: 31.00%\n",
      "Progress: 32.00%\n",
      "Progress: 33.00%\n",
      "Progress: 34.00%\n",
      "Progress: 35.00%\n",
      "Progress: 36.00%\n",
      "Progress: 37.00%\n",
      "Progress: 38.00%\n",
      "Progress: 39.00%\n",
      "Progress: 40.00%\n",
      "Progress: 41.00%\n",
      "Progress: 42.00%\n",
      "Progress: 43.00%\n",
      "Progress: 44.00%\n",
      "Progress: 45.00%\n",
      "Progress: 46.00%\n",
      "Progress: 47.00%\n",
      "Progress: 48.00%\n",
      "Progress: 49.00%\n",
      "Progress: 50.00%\n",
      "Progress: 51.00%\n",
      "Progress: 52.00%\n",
      "Progress: 53.00%\n",
      "Progress: 54.00%\n",
      "Progress: 55.00%\n",
      "Progress: 56.00%\n",
      "Progress: 57.00%\n",
      "Progress: 58.00%\n",
      "Progress: 59.00%\n",
      "Progress: 60.00%\n",
      "Progress: 61.00%\n",
      "Progress: 62.00%\n",
      "Progress: 63.00%\n",
      "Progress: 64.00%\n",
      "Progress: 65.00%\n",
      "Progress: 66.00%\n",
      "Progress: 67.00%\n",
      "Progress: 68.00%\n",
      "Progress: 69.00%\n",
      "Progress: 70.00%\n",
      "Progress: 71.00%\n",
      "Progress: 72.00%\n",
      "Progress: 73.00%\n",
      "Progress: 74.00%\n",
      "Progress: 75.00%\n",
      "Progress: 76.00%\n",
      "Progress: 77.00%\n",
      "Progress: 78.00%\n",
      "Progress: 79.00%\n",
      "Progress: 80.00%\n",
      "Progress: 81.00%\n",
      "Progress: 82.00%\n",
      "Progress: 83.00%\n",
      "Progress: 84.00%\n",
      "Progress: 85.00%\n",
      "Progress: 86.00%\n",
      "Progress: 87.00%\n",
      "Progress: 88.00%\n",
      "Progress: 89.00%\n",
      "Progress: 90.00%\n",
      "Progress: 91.00%\n",
      "Progress: 92.00%\n",
      "Progress: 93.00%\n",
      "Progress: 94.00%\n",
      "Progress: 95.00%\n",
      "Progress: 96.00%\n",
      "Progress: 97.00%\n",
      "Progress: 98.00%\n",
      "Progress: 99.00%\n",
      "Progress: 100.00%\n",
      "Done building KDTree\n",
      "Done querying KDTree\n",
      "Progress: 0.00%\n",
      "Progress: 1.00%\n",
      "Progress: 2.00%\n",
      "Progress: 3.00%\n",
      "Progress: 4.00%\n",
      "Progress: 5.00%\n",
      "Progress: 6.00%\n",
      "Progress: 7.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m k_neighbors_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m25\u001b[39m] \n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k_neighbors \u001b[38;5;129;01min\u001b[39;00m k_neighbors_list: \n\u001b[0;32m---> 10\u001b[0m     normals \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_normals\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_neighbors\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     11\u001b[0m     map_normals_curvature \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mconcatenate((\u001b[38;5;28mmap\u001b[39m, normals), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mny\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mna\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnc\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m     12\u001b[0m     fileout \u001b[38;5;241m=\u001b[39m filepath\u001b[38;5;241m.\u001b[39mreplace(filetype, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_with_normals_neighbors_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \n",
      "Cell \u001b[0;32mIn[6], line 172\u001b[0m, in \u001b[0;36mcompute_normals\u001b[0;34m(data, k)\u001b[0m\n\u001b[1;32m    169\u001b[0m centered_neighbors \u001b[38;5;241m=\u001b[39m neighbors \u001b[38;5;241m-\u001b[39m point\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Perform PCA using Singular Value Decomposition (SVD)\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m covariance_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcentered_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigh(covariance_matrix)  \u001b[38;5;66;03m# Eigenvalues and eigenvectors\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# The normal vector is the eigenvector corresponding to the smallest eigenvalue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mujoco_env/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:2773\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2771\u001b[0m     X_T \u001b[38;5;241m=\u001b[39m (X\u001b[38;5;241m*\u001b[39mw)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   2772\u001b[0m c \u001b[38;5;241m=\u001b[39m dot(X, X_T\u001b[38;5;241m.\u001b[39mconj())\n\u001b[0;32m-> 2773\u001b[0m c \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrue_divide\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# threshold_list = [0.1, 0.2, 0.3, 0.4, 0.5] \n",
    "# for threshold in threshold_list: \n",
    "#     normals, curvature, mean_curvature = compute_normals_and_curvature_within_threshold(map, threshold) \n",
    "#     map_normals_curvature = pd.DataFrame(data=np.concatenate((map, normals, curvature.reshape(-1, 1), mean_curvature.reshape(-1, 1)), axis=1), columns=['x', 'y', 'z', 'a', 'b', 'c', 'nx', 'ny', 'nz', 'na', 'nb', 'nc', 'curvature', 'mean_curvature']) \n",
    "#     fileout = filepath.replace(filetype, f\"_with_normals_threshold_{threshold}.csv\")    \n",
    "#     map_normals_curvature.to_csv(fileout, index=False) \n",
    "\n",
    "k_neighbors_list = [10, 15, 20, 25] \n",
    "for k_neighbors in k_neighbors_list: \n",
    "    normals = compute_normals(map, k_neighbors) \n",
    "    map_normals_curvature = pd.DataFrame(data=np.concatenate((map, normals), axis=1), columns=['x', 'y', 'z', 'a', 'b', 'c', 'nx', 'ny', 'nz', 'na', 'nb', 'nc']) \n",
    "    fileout = filepath.replace(filetype, f\"_with_normals_neighbors_{k_neighbors}.csv\")   \n",
    "    map_normals_curvature.to_csv(fileout, index=False)\n",
    "    fileout = filepath.replace(filetype, f\"_with_normals_neighbors_{k_neighbors}.pkl\") \n",
    "    map_normals_curvature.to_pickle(fileout) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
